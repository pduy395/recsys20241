{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../input/h-and-m-personalized-fashion-recommendations/'\n",
    "csv_train = f'{base_path}transactions_train.csv'\n",
    "csv_sub = f'{base_path}sample_submission.csv'\n",
    "csv_users = f'{base_path}customers.csv'\n",
    "csv_items = f'{base_path}articles.csv'\n",
    "\n",
    "df = pd.read_csv(csv_train, dtype={'article_id': str}, parse_dates=['t_dat'])\n",
    "df_sub = pd.read_csv(csv_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = pd.read_csv(csv_users)\n",
    "dfi = pd.read_csv(csv_items, dtype={'article_id': str})\n",
    "\n",
    "ALL_USERS = dfu['customer_id'].unique().tolist()\n",
    "ALL_ITEMS = dfi['article_id'].unique().tolist()\n",
    "\n",
    "user_to_customer_map = {user_id: customer_id for user_id, customer_id in enumerate(ALL_USERS)}\n",
    "customer_to_user_map = {customer_id: user_id for user_id, customer_id in enumerate(ALL_USERS)}\n",
    "\n",
    "item_to_article_map = {item_id: article_id for item_id, article_id in enumerate(ALL_ITEMS)}\n",
    "article_to_item_map = {article_id: item_id for item_id, article_id in enumerate(ALL_ITEMS)}\n",
    "\n",
    "del dfu, dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df['customer_id'].map(customer_to_user_map)\n",
    "df['item_id'] = df['article_id'].map(article_to_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SIMILAR_USERS = 30\n",
    "\n",
    "MINIMUM_PURCHASES = 3\n",
    "\n",
    "START_DATE = '2020-08-21'\n",
    "\n",
    "DROP_PURCHASED_ITEMS = False\n",
    "\n",
    "DROP_USER_FROM_HIS_NEIGHBORHOOD = False\n",
    "\n",
    "TEST_RUN = False\n",
    "\n",
    "TEST_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    \"\"\" Flatten a list of lists\"\"\"\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def compare_vectors(v1, v2):\n",
    "    \"\"\"Compare lists of purchased product for two given users\n",
    "    v1 stands for the \"vector representation for user 1\", which is a list of the purchases of u1\n",
    "    \n",
    "    Returns:\n",
    "        A value between 0 and 1 (similarity)\n",
    "    \"\"\"\n",
    "    intersection = len(set(v1) & set(v2))\n",
    "    denominator = np.sqrt(len(v1) * len(v2))\n",
    "    return intersection / denominator\n",
    "\n",
    "def get_similar_users(u, v, dfh):\n",
    "    \"\"\"\n",
    "    Get the N_SIMILAR_USERS most similar users to the given one with their similarity score\n",
    "    Arguments:\n",
    "        u: the user_id, \n",
    "        v:  the \"vector\" representation of the user (list of item_id)\n",
    "        dfh : the \"history of transaccions\" dataframe\n",
    "        \n",
    "    Returns:\n",
    "        tuple of lists ([similar user_id], [similarity scores])\n",
    "    \"\"\"\n",
    "    similar_users = dfh.apply(lambda v_other: compare_vectors(v, v_other)).sort_values(ascending=False).head(N_SIMILAR_USERS + 1)\n",
    "    \n",
    "    if DROP_USER_FROM_HIS_NEIGHBORHOOD:\n",
    "        similar_users = similar_users[similar_users.index != u]\n",
    "        \n",
    "    return similar_users.index.tolist(), similar_users.tolist()\n",
    "\n",
    "def get_items(u, v, dfh):\n",
    "    \"\"\" Get the recommend items for a given users\n",
    "    \n",
    "    It will:\n",
    "        1) Get similar users for the given user\n",
    "        2) Obtain all the items those users purchased\n",
    "        3) Rank them using the similarity scores of the user that purchased them\n",
    "        4) Return the 12 best ranked\n",
    "    \n",
    "    Arguments:\n",
    "        u: the user_id, \n",
    "        v:  the \"vector\" representation of the user (list of item_id)\n",
    "        dfh : the \"history of transaccions\" dataframe\n",
    "        \n",
    "    Returns:\n",
    "        list of item_id of lenght at most 12\n",
    "    \"\"\"\n",
    "    global i, n\n",
    "    \n",
    "    users, scores = get_similar_users(u, v, dfh)\n",
    "    df_nn = pd.DataFrame({'user': users, 'score': scores})\n",
    "    df_nn['items'] = df_nn.apply(lambda row: dfh.loc[row.user], axis=1)\n",
    "    df_nn['weighted_items'] = df_nn.apply(lambda row: [(item, row.score) for item in row['items']], axis=1)\n",
    "\n",
    "    recs = pd.DataFrame(flatten(df_nn['weighted_items'].tolist()), columns=['item', 'score']).groupby('item')['score'].sum().sort_values(ascending=False)\n",
    "    if DROP_PURCHASED_ITEMS:\n",
    "        recs = recs[~recs.index.isin(v)]\n",
    "    # Keep the first 12 and get the item_ids\n",
    "    i +=1\n",
    "    if i % 200 == 0:\n",
    "        pid = mp.current_process().pid\n",
    "        print(f\"[PID {pid:>2d}] Finished {i:3d} / {n:5d} - {i/n*100:3.0f}%\")\n",
    "    return recs.head(12).index.tolist()\n",
    "\n",
    "def get_items_chunk(user_ids: np.array, dfh: pd.DataFrame):\n",
    "    \"\"\" Call get_item for a list of user_ids\n",
    "    \n",
    "    Arguments:\n",
    "        user_ids: list of user_id, \n",
    "        dfh: the \"history of transaccions\" dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series with index user_id and list of item_id (recommendations) as value\n",
    "    \"\"\"\n",
    "    global i, n\n",
    "    i = 0\n",
    "    \n",
    "    n = len(user_ids)\n",
    "    pid = mp.current_process().pid\n",
    "    print(f\"[PID {pid:>2d}] Started working with {n:5d} users\")\n",
    "    \n",
    "    df_user_vectors = pd.DataFrame(dfh.loc[user_ids]).reset_index()\n",
    "    df_user_vectors['recs'] = df_user_vectors.apply(lambda row: get_items(row.user_id, row.item_id, dfh), axis=1)\n",
    "    return df_user_vectors.set_index('user_id')['recs']\n",
    "\n",
    "def get_recommendations(users: list, dfh: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Obtained recommendation for the users using transaccion dfh in a parallelized manner\n",
    "    \n",
    "    Call get_items_chunk in a \"smart\" multiprocessing fashion\n",
    "    \n",
    "    Arguments:\n",
    "        users: list of user_id\n",
    "        dfh: the \"history of transaccions\" dataframe\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame with index user_id and list of item_id (recommendations) as value\n",
    "    \n",
    "    \"\"\"\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Split into approximately evenly sized chunks\n",
    "    # We will send just one batch to each CPU \n",
    "    user_chunks = np.array_split(users, mp.cpu_count())\n",
    "    \n",
    "    f = partial(get_items_chunk, dfh=dfh)\n",
    "    with Pool(mp.cpu_count()) as p:\n",
    "        res = p.map(f, user_chunks)\n",
    "    \n",
    "    df_rec = pd.DataFrame(pd.concat(res))\n",
    "\n",
    "    elapsed = (time.time() - time_start) / 60\n",
    "    print(f\"Finished get_recommendations({len(users)}). It took {elapsed:5.2f} mins\")\n",
    "    return df_rec\n",
    "\n",
    "\n",
    "def uucf(df, start_date=START_DATE):\n",
    "    \"\"\" Entry point for the UUCF model. \n",
    "    \n",
    "    Receive the original transactions_train.csv and a start_date and gets UUCF recommendations\n",
    "    \n",
    "    The model will not cover the full list of users, but just a subset of them.\n",
    "    \n",
    "    It will provide recommendations for users with at least MINIMUM_PURCHASES after start_date.\n",
    "    It might return less than 12 recs per user.\n",
    "    \n",
    "    An ad-hoc function for filling these gaps should be used downstream.\n",
    "    (See fill functionality right below)\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "        df: The raw dataframe from transactions_train.csv\n",
    "        start_date: a date\n",
    "        \n",
    "    Returns:\n",
    "        a submission-like pd.DataFrame with columns [customer_id, prediction]\n",
    "        'prediction' is a list and not a string though\n",
    "    \n",
    "    \"\"\"\n",
    "    df_small = df[df['t_dat'] > start_date]\n",
    "    print(f\"Kept data from {start_date} on. Total rows: {len(df_small)}\")\n",
    "    \n",
    "    # H stands for \"Transaction history\"\n",
    "    # dfh is a series of user_id => list of item_id (the list of purchases in order)\n",
    "    dfh = df_small.groupby(\"user_id\")['item_id'].apply(lambda items: list(set(items)))\n",
    "    dfh = dfh[dfh.str.len() >= MINIMUM_PURCHASES]\n",
    "    if TEST_RUN:\n",
    "        print(\"WARNING: TEST_RUN is True. It will be a toy execution.\")\n",
    "        dfh = dfh.head(TEST_SIZE)\n",
    "    \n",
    "    users = dfh.index.tolist()\n",
    "    n_users = len(users)\n",
    "    print(f\"Total users in the time frame with at least {MINIMUM_PURCHASES}: {n_users}\")\n",
    "    \n",
    "    df_rec = get_recommendations(users, dfh)\n",
    "    df_rec['customer_id'] = df_rec.index.map(user_to_customer_map)\n",
    "    df_rec['prediction'] = df_rec['recs'].map(lambda l: [item_to_article_map[i] for i in l])\n",
    "    \n",
    "    # Submission ready dataframe\n",
    "    df_rec.reset_index(drop=True)[['customer_id', 'prediction']]\n",
    "    return df_rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recs = uucf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fill = '../input/h-m-content-based-12-most-popular-items-0-007/submission.csv'\n",
    "df_fill = pd.read_csv(csv_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(seq):\n",
    "    \"\"\" Remove duplicates of a given sequence keeping order\"\"\"\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def fill_row(row):\n",
    "    uucf = row['prediction_uucf']\n",
    "    fill = row['prediction_fill'].split()\n",
    "    new_list = drop_duplicates(uucf + fill)[:12]\n",
    "    return ' '.join(new_list)\n",
    "\n",
    "\n",
    "def fill(df_recs, df_fill):\n",
    "    df_recs['len'] = df_recs['prediction'].str.len()\n",
    "    df_recs = pd.merge(df_fill, df_recs, how='left', on='customer_id', suffixes=('_fill', '_uucf'))\n",
    "    \n",
    "    \n",
    "    # No recs from UUCF at all: use the fallback model \n",
    "    df_recs.loc[df_recs['prediction_uucf'].isnull(), 'prediction'] = df_recs['prediction_fill']\n",
    "\n",
    "\n",
    "    # Full UUCF recommendation\n",
    "    mask = df_recs['prediction_uucf'].notnull() & (df_recs['len'] == 12)\n",
    "    df_recs.loc[mask, 'prediction'] = df_recs['prediction_uucf']\n",
    "\n",
    "\n",
    "    # Fill with another model. Not enough recs from UUCF\n",
    "    fill_mask = df_recs['prediction_uucf'].notnull() & (df_recs['len'] < 12)\n",
    "    df_recs.loc[fill_mask, 'prediction'] = df_recs[fill_mask].apply(fill_row, axis=1)\n",
    "    return df_recs.drop(['prediction_uucf', 'prediction_fill', 'len', 'recs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with another model\n",
    "df_sub = fill(df_recs, df_fill)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit\n",
    "df_sub.to_csv(\"uucf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
